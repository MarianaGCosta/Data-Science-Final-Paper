{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqzR45hSRuF/06SnsdXmEZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarianaGCosta/Processamento-de-dados-em-portugues-brasileiro/blob/main/proveniencia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importação das bibliotecas"
      ],
      "metadata": {
        "id": "biJgofkWUuPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install prov\n",
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrR5a6lLQs0e",
        "outputId": "66c8b545-8f99-4c12-9463-b5053d06523e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting prov\n",
            "  Downloading prov-2.0.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from prov) (2.8.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from prov) (3.4.2)\n",
            "Requirement already satisfied: lxml>=3.3.5 in /usr/local/lib/python3.10/dist-packages (from prov) (5.3.0)\n",
            "Collecting rdflib<7,>=4.2.1 (from prov)\n",
            "  Downloading rdflib-6.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.2->prov) (1.17.0)\n",
            "Collecting isodate<0.7.0,>=0.6.0 (from rdflib<7,>=4.2.1->prov)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib<7,>=4.2.1->prov) (3.2.0)\n",
            "Downloading prov-2.0.1-py3-none-any.whl (421 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: isodate, rdflib, prov\n",
            "Successfully installed isodate-0.6.1 prov-2.0.1 rdflib-6.3.2\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from prov.model import ProvDocument\n",
        "from graphviz import Digraph\n",
        "from prov.dot import prov_to_dot\n",
        "from unidecode import unidecode\n",
        "import datetime"
      ],
      "metadata": {
        "id": "_7m7OdhzQhRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prov-model do pré-processamento dos dados"
      ],
      "metadata": {
        "id": "9ZQhdQbNU0jU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ViTolh0NnYv",
        "outputId": "8dcb6a60-724e-4371-a3e4-150216879323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O gráfico será salvo em: assets/img/Pré-processamento_Corpus_DeG.png\n",
            "Arquivo PROV gerado: assets/img/Pré-processamento_Corpus_DeG.png\n"
          ]
        }
      ],
      "source": [
        "def sanitize_label(label):\n",
        "  \"\"\"Função para remover caracteres especiais e quebras de linha do rótulo\"\"\"\n",
        "  return unidecode(label.replace(\"\\n\", \" \").replace(\"\\r\", \" \"))\n",
        "\n",
        "def create_agents(d1):\n",
        "  \"\"\"Função para criar os agentes de proveniência\"\"\"\n",
        "  agents = {}\n",
        "  agents[\"ufrj\"] = d1.agent(\n",
        "      \"ufrj:UFRJ\",\n",
        "      {\n",
        "          \"prov:type\": \"prov:Organization\",\n",
        "          \"foaf:name\": sanitize_label(\"Universidade Federal do Rio de Janeiro\"),\n",
        "      },\n",
        "  )\n",
        "\n",
        "  agents[\"uff\"] = d1.agent(\n",
        "      \"uff:UFF\",\n",
        "      {\n",
        "          \"prov:type\": \"prov:Organization\",\n",
        "          \"foaf:name\": sanitize_label(\"Universidade Federal Fluminense\"),\n",
        "      },\n",
        "  )\n",
        "\n",
        "  agents[\"ppgi\"] = d1.agent(\n",
        "      \"ufrj:PPGI\",\n",
        "      {\n",
        "          \"prov:type\": \"prov:Organization\",\n",
        "          \"foaf:name\": sanitize_label(\"Programa de Pós-Graduação em Informática\"),\n",
        "      },\n",
        "  )\n",
        "\n",
        "  agents[\"mai803\"] = d1.agent(\n",
        "      \"ufrj:MAI803\",\n",
        "      {\n",
        "          \"prov:type\": \"prov:Organization\",\n",
        "          \"foaf:name\": sanitize_label(\n",
        "              \"Tópicos Especiais em Sistemas Complexos - Disciplina de Fundamentos de Ciência de Dados\"\n",
        "          ),\n",
        "      },\n",
        "  )\n",
        "\n",
        "  agents[\"developer\"] = d1.agent(\n",
        "      \"ufrj:MGC\",\n",
        "      {\n",
        "          \"prov:type\": \"prov:Person\",\n",
        "          \"foaf:name\": sanitize_label(\"Mariana Gonçalves\"),\n",
        "          \"foaf:mbox\": \"marianag.costta@gmail.com\",\n",
        "      },\n",
        "  )\n",
        "\n",
        "  agents[\"script\"] = d1.agent(\n",
        "      \"ufrj:getProv.py\",\n",
        "      {\"prov:type\": \"prov:SoftwareAgent\", \"foaf:name\": \"getProv.py\"},\n",
        "  )\n",
        "\n",
        "  # Relacionando os agentes\n",
        "  d1.actedOnBehalfOf(agents[\"ppgi\"], agents[\"ufrj\"])\n",
        "  d1.actedOnBehalfOf(agents[\"mai803\"], agents[\"ppgi\"])\n",
        "  d1.actedOnBehalfOf(agents[\"developer\"], agents[\"mai803\"])\n",
        "  d1.actedOnBehalfOf(agents[\"script\"], agents[\"developer\"])\n",
        "\n",
        "  return agents\n",
        "\n",
        "\n",
        "def generate_prov_document(nome_arquivo):\n",
        "  d1 = ProvDocument()\n",
        "  d1.add_namespace(\"ufrj\", \"https://www.ufrj.br\")\n",
        "  d1.add_namespace(\"foaf\", \"http://xmlns.com/foaf/0.1/\")\n",
        "  d1.add_namespace(\"uff\", \"https://www.uff.br\")\n",
        "\n",
        "  agents = create_agents(d1)\n",
        "  entities = {}\n",
        "  activities = {}\n",
        "\n",
        "  # Entidades (datasets)\n",
        "  entities[\"Corpus_DEG\"] = d1.entity(\n",
        "          \"uff:Corpus_DEG\",\n",
        "          {\n",
        "              \"prov:label\": sanitize_label(\"Processamento de dados Corpus DeG\"),\n",
        "              \"prov:type\": \"foaf:Document\",\n",
        "              \"prov:location\": \"https://deg.uff.br/corpus-dg/\",\n",
        "          },\n",
        "      )\n",
        "\n",
        "  # Atividade de importação\n",
        "  entities[\"Juiz de Fora\"] = d1.entity(\n",
        "    \"uff:Juiz_de_Fora\",\n",
        "      {\n",
        "        \"prov:label\": sanitize_label(\"SubCorpus Juiz de Fora\"),\n",
        "        \"prov:type\": \"foaf:Document\",\n",
        "        \"prov:location\": \"https://deg.uff.br/corpus-dg/\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "  entities[\"Natal\"] = d1.entity(\n",
        "      \"uff:Natal\",\n",
        "        {\n",
        "        \"prov:label\": sanitize_label(\"SubCorpus Natal\"),\n",
        "        \"prov:type\": \"foaf:Document\",\n",
        "        \"prov:location\": \"https://deg.uff.br/corpus-dg/\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "  entities[\"Niteroi\"] = d1.entity(\n",
        "      \"uff:Niteroi\",\n",
        "        {\"prov:label\": sanitize_label(\"SubCorpus Niteroi\"),\n",
        "        \"prov:type\": \"foaf:Document\",\n",
        "        \"prov:location\": \"https://deg.uff.br/corpus-dg/\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "  entities[\"Rio de Janeiro A\"] = d1.entity(\n",
        "      \"uff:Rio_de_Janeiro_A\",\n",
        "        {\"prov:label\": sanitize_label(\"SubCorpus Rio de Janeiro A\"),\n",
        "        \"prov:type\": \"foaf:Document\",\n",
        "        \"prov:location\": \"https://deg.uff.br/corpus-dg/\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "  entities[\"Rio de Janeiro B\"] = d1.entity(\n",
        "      \"uff:Rio_de_Janeiro_B\",\n",
        "        {\"prov:label\": sanitize_label(\"SubCorpus Rio de Janeiro B\"),\n",
        "        \"prov:type\": \"foaf:Document\",\n",
        "        \"prov:location\": \"https://deg.uff.br/corpus-dg/\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "  entities[\"Rio Grande\"] = d1.entity(\n",
        "      \"uff:Rio_Grande\",\n",
        "        {\"prov:label\": sanitize_label(\"SubCorpus Rio Grande\"),\n",
        "        \"prov:type\": \"foaf:Document\",\n",
        "        \"prov:location\": \"https://deg.uff.br/corpus-dg/\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "  # Atividade de pre-processamento\n",
        "  activities[\"pre_processamento\"] = d1.activity(\n",
        "      \"ufrj:pre_processamento\", startTime=datetime.datetime.now()\n",
        "  )\n",
        "  d1.used(activities[\"pre_processamento\"], entities[\"Corpus_DEG\"])\n",
        "\n",
        "  # Entidades de resultados processados\n",
        "  results = {\n",
        "      \"baseconjugada\" : \"pre_processamento da base conjugada\",\n",
        "      \"juizdefoda\" : \"pre_processamento da base Juiz de Fora\",\n",
        "      \"natal_\" : \"pre_processamento da base Natal\",\n",
        "      \"niteroi_\" : \"pre_processamento da base Niteroi\",\n",
        "      \"riodejaneiroa\" : \"pre_processamento da base Rio de Janeiro A\",\n",
        "      \"riodejaneirob\" : \"pre_processamento da base Rio de Janeiro B\",\n",
        "      \"rio_grande\" : \"pre_processamento da base Rio Grande\"}\n",
        "\n",
        "\n",
        "  for key, label in results.items():\n",
        "      entities[key] = d1.entity(\n",
        "          f\"ufrj:{key}\",\n",
        "          {\"prov:label\": sanitize_label(label), \"prov:type\": \"prov:Entity\"},\n",
        "      )\n",
        "      d1.wasGeneratedBy(entities[key], activities[\"pre_processamento\"])\n",
        "\n",
        "  # Atividade de visualização\n",
        "  activities[\"visualization\"] = d1.activity(\n",
        "      \"ufrj:visualizacao\", startTime=datetime.datetime.now()\n",
        "  )\n",
        "  d1.used(activities[\"visualization\"], entities[\"Corpus_DEG\"])\n",
        "\n",
        "  # Resultado da visualização\n",
        "  entities[\"visualization_output\"] = d1.entity(\n",
        "      \"ufrj:visualizacao-output\",\n",
        "      {\n",
        "          \"prov:label\": sanitize_label(\"Resultado da Visualização\"),\n",
        "          \"prov:type\": \"prov:Entity\",\n",
        "      },\n",
        "  )\n",
        "  d1.wasGeneratedBy(entities[\"visualization_output\"], activities[\"visualization\"])\n",
        "\n",
        "  # Associações\n",
        "  d1.wasAssociatedWith(activities[\"pre_processamento\"], agents[\"developer\"])\n",
        "  d1.wasAssociatedWith(activities[\"pre_processamento\"], agents[\"script\"])\n",
        "  d1.wasAssociatedWith(activities[\"visualization\"], agents[\"developer\"])\n",
        "\n",
        "  # Salvar gráfico PROV\n",
        "  img_dir = \"assets/img\"\n",
        "  os.makedirs(img_dir, exist_ok=True)\n",
        "  output_path = os.path.join(img_dir, f\"{nome_arquivo}.png\")\n",
        "  print(f\"O gráfico será salvo em: {output_path}\")\n",
        "  dot = prov_to_dot(d1)\n",
        "  dot.write_png(output_path)\n",
        "\n",
        "  return output_path\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  prov_image_path = generate_prov_document(\"Pré-processamento_Corpus_DeG\")\n",
        "  print(f\"Arquivo PROV gerado: {prov_image_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prov-model da lematização dos dados"
      ],
      "metadata": {
        "id": "A6B_-gBcU6uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sanitize_label(label):\n",
        "    \"\"\"Função para remover caracteres especiais e quebras de linha do rótulo\"\"\"\n",
        "    return unidecode(label.replace(\"\\n\", \" \").replace(\"\\r\", \" \"))\n",
        "\n",
        "\n",
        "def create_agents(d1):\n",
        "    \"\"\"Função para criar os agentes de proveniência\"\"\"\n",
        "    agents = {}\n",
        "    agents[\"ufrj\"] = d1.agent(\n",
        "        \"ufrj:UFRJ\",\n",
        "        {\n",
        "            \"prov:type\": \"prov:Organization\",\n",
        "            \"foaf:name\": sanitize_label(\"Universidade Federal do Rio de Janeiro\"),\n",
        "        },\n",
        "    )\n",
        "\n",
        "    agents[\"ppgi\"] = d1.agent(\n",
        "        \"ufrj:PPGI\",\n",
        "        {\n",
        "            \"prov:type\": \"prov:Organization\",\n",
        "            \"foaf:name\": sanitize_label(\"Programa de Pós-Graduação em Informática\"),\n",
        "        },\n",
        "    )\n",
        "\n",
        "    agents[\"mai803\"] = d1.agent(\n",
        "        \"ufrj:MAI803\",\n",
        "        {\n",
        "            \"prov:type\": \"prov:Organization\",\n",
        "            \"foaf:name\": sanitize_label(\n",
        "                \"Tópicos Especiais em Sistemas Complexos - Disciplina de Fundamentos de Ciência de Dados\"\n",
        "            ),\n",
        "        },\n",
        "    )\n",
        "\n",
        "    agents[\"developer\"] = d1.agent(\n",
        "        \"ufrj:MGC\",\n",
        "        {\n",
        "            \"prov:type\": \"prov:Person\",\n",
        "            \"foaf:name\": sanitize_label(\"Mariana Gonçalves\"),\n",
        "            \"foaf:mbox\": \"marianag.costta@gmail.com\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "    agents[\"script\"] = d1.agent(\n",
        "        \"ufrj:getProv.py\",\n",
        "        {\"prov:type\": \"prov:SoftwareAgent\", \"foaf:name\": \"getProv.py\"},\n",
        "    )\n",
        "\n",
        "    # Relacionando os agentes\n",
        "    d1.actedOnBehalfOf(agents[\"ppgi\"], agents[\"ufrj\"])\n",
        "    d1.actedOnBehalfOf(agents[\"mai803\"], agents[\"ppgi\"])\n",
        "    d1.actedOnBehalfOf(agents[\"developer\"], agents[\"mai803\"])\n",
        "    d1.actedOnBehalfOf(agents[\"script\"], agents[\"developer\"])\n",
        "\n",
        "    return agents\n",
        "\n",
        "\n",
        "def generate_prov_document(nome_arquivo):\n",
        "    try:\n",
        "        # Criar o documento PROV\n",
        "        d1 = ProvDocument()\n",
        "        d1.add_namespace(\"ufrj\", \"https://www.ufrj.br\")\n",
        "        d1.add_namespace(\"foaf\", \"http://xmlns.com/foaf/0.1/\")\n",
        "\n",
        "        agents = create_agents(d1)\n",
        "        entities = {}\n",
        "        activities = {}\n",
        "\n",
        "        # Entidades (subcorpus)\n",
        "        entities[\"Rio Grande\"] = d1.entity(\n",
        "        \"ufrj:rio_grande\",\n",
        "        {\"prov:label\": sanitize_label(\"SubCorpus Rio Grande\"),\n",
        "        \"prov:type\": \"foaf:Document\",\n",
        "        \"prov:location\": \"corpus_DeG/riogrande.json\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "        entities[\"Rio Grande sem stopwords\"] = d1.entity(\n",
        "        \"ufrj:rio_grande_sem_stopwords\",\n",
        "        {\"prov:label\": sanitize_label(\"SubCorpus Rio Grande semstopwords\"),\n",
        "        \"prov:type\": \"foaf:Document\",\n",
        "        \"prov:location\": \"corpus_DeG/riogrande_stop.json\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "        # Atividade de lematização\n",
        "        activities[\"lematizacao_spacy\"] = d1.activity(\n",
        "            \"ufrj:lematizacao_spacy\", startTime=datetime.datetime.now()\n",
        "        )\n",
        "        d1.used(activities[\"lematizacao_spacy\"], entities[\"Rio Grande\"])\n",
        "        d1.used(activities[\"lematizacao_spacy\"], entities[\"Rio Grande sem stopwords\"])\n",
        "\n",
        "        activities[\"lematizacao_simplemma\"] = d1.activity(\n",
        "            \"ufrj:lematizacao_simplemma\", startTime=datetime.datetime.now()\n",
        "        )\n",
        "        d1.used(activities[\"lematizacao_simplemma\"], entities[\"Rio Grande\"])\n",
        "        d1.used(activities[\"lematizacao_simplemma\"], entities[\"Rio Grande sem stopwords\"])\n",
        "\n",
        "        activities[\"lematizacao_portilexicon\"] = d1.activity(\n",
        "            \"ufrj:lematizacao_portilexicon\", startTime=datetime.datetime.now()\n",
        "        )\n",
        "        d1.used(activities[\"lematizacao_portilexicon\"], entities[\"Rio Grande\"])\n",
        "        d1.used(activities[\"lematizacao_portilexicon\"], entities[\"Rio Grande sem stopwords\"])\n",
        "\n",
        "        # Entidades de resultados processados\n",
        "        results = {\n",
        "            \"lema_spacy1\": \"Lematização SpaCy\",\n",
        "            \"lema_spacy2\": \"Lematização SpaCy sem stopwords\",\n",
        "            \"lema_simp1\": \"Lematização Simplemma\",\n",
        "            \"lema_simp2\": \"Lematização Simplemma sem stopwords\",\n",
        "            \"lema_port1\": \"Lematização Portilexicon\",\n",
        "            \"lema_port2\": \"Lematização Portilexicon sem stopwords\",\n",
        "        }\n",
        "\n",
        "        for key, label in results.items():\n",
        "            entities[key] = d1.entity(\n",
        "                f\"ufrj:{key}\",\n",
        "                {\"prov:label\": sanitize_label(label), \"prov:type\": \"prov:Entity\"},\n",
        "            )\n",
        "            d1.wasGeneratedBy(entities[key], activities[\"lematizacao_spacy\"])\n",
        "            d1.wasGeneratedBy(entities[key], activities[\"lematizacao_simplemma\"])\n",
        "            d1.wasGeneratedBy(entities[key], activities[\"lematizacao_portilexicon\"])\n",
        "\n",
        "        # Atividade de visualização\n",
        "        activities[\"visualization\"] = d1.activity(\n",
        "            \"ufrj:visualizacao\", startTime=datetime.datetime.now()\n",
        "        )\n",
        "        d1.used(activities[\"visualization\"], entities[\"Rio Grande\"])\n",
        "        d1.used(activities[\"visualization\"], entities[\"Rio Grande sem stopwords\"])\n",
        "\n",
        "        # Resultado da visualização\n",
        "        entities[\"visualization_output\"] = d1.entity(\n",
        "            \"ufrj:visualizacao-output\",\n",
        "            {\n",
        "                \"prov:label\": sanitize_label(\"Resultado da Visualização\"),\n",
        "                \"prov:type\": \"prov:Entity\",\n",
        "            },\n",
        "        )\n",
        "        d1.wasGeneratedBy(entities[\"visualization_output\"], activities[\"visualization\"])\n",
        "\n",
        "        # Associações\n",
        "        d1.wasAssociatedWith(activities[\"lematizacao_spacy\"], agents[\"developer\"])\n",
        "        d1.wasAssociatedWith(activities[\"lematizacao_spacy\"], agents[\"script\"])\n",
        "        d1.wasAssociatedWith(activities[\"visualization\"], agents[\"developer\"])\n",
        "\n",
        "        d1.wasAssociatedWith(activities[\"lematizacao_simplemma\"], agents[\"developer\"])\n",
        "        d1.wasAssociatedWith(activities[\"lematizacao_simplemma\"], agents[\"script\"])\n",
        "        d1.wasAssociatedWith(activities[\"visualization\"], agents[\"developer\"])\n",
        "\n",
        "        d1.wasAssociatedWith(activities[\"lematizacao_portilexicon\"], agents[\"developer\"])\n",
        "        d1.wasAssociatedWith(activities[\"lematizacao_portilexicon\"], agents[\"script\"])\n",
        "        d1.wasAssociatedWith(activities[\"visualization\"], agents[\"developer\"])\n",
        "\n",
        "\n",
        "        # Salvar gráfico PROV\n",
        "        img_dir = \"assets/img\"\n",
        "        os.makedirs(img_dir, exist_ok=True)\n",
        "        output_path = os.path.join(img_dir, f\"{nome_arquivo}.png\")\n",
        "        print(f\"O gráfico será salvo em: {output_path}\")\n",
        "        dot = prov_to_dot(d1)\n",
        "        dot.write_png(output_path)\n",
        "\n",
        "        return output_path\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None  # Or raise the exception if you prefer\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  prov_image_path = generate_prov_document(\"Lematizacao Rio Grande\")\n",
        "  print(f\"Arquivo PROV gerado: {prov_image_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLDeYgV8Qdr0",
        "outputId": "f903ccd3-3ba8-4378-906d-334da4bca687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O gráfico será salvo em: assets/img/Lematizacao Rio Grande.png\n",
            "Arquivo PROV gerado: assets/img/Lematizacao Rio Grande.png\n"
          ]
        }
      ]
    }
  ]
}